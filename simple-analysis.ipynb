{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Time Series Analysis\n",
    "\n",
    "This notebook demonstrates basic time series data analysis using scientific Python libraries such as [NumPY](http://www.numpy.org/).  This example uses air temperature data that is stored in HydroShare to derive daily aggregated values and store them in a new HydroShare resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Script Setup and Preparation\n",
    "\n",
    "Before we begin our processing, we must import several libaries into this notebook.  The `%matplotlib inline` command tells the notebook server to place plots and figures directly into the notebook.\n",
    "\n",
    "**Note:** You may see some matplotlib warnings if this is the first time you are running this notebook. These warnings can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import itertools as it\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This resource contains a file with observation data called `BeaverDivideTemp.csv`\n",
    "\n",
    "We'll use this file to derive daily minimum, maximum, and average air temperatures.  Lets preview this Beaver Divide temperature data by looping over the first 10 lines of the csv file that was downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,AirTemp-degC\n",
      "\n",
      "10-30-2013 10:15:00, 20.91 \n",
      "\n",
      "10-30-2013 12:00:00, 21.62 \n",
      "\n",
      "10-30-2013 12:15:00, 21.87 \n",
      "\n",
      "10-30-2013 12:30:00, 21.92 \n",
      "\n",
      "10-31-2013 09:15:00, -174.4 \n",
      "\n",
      "10-31-2013 09:30:00, -9999 \n",
      "\n",
      "10-31-2013 09:45:00, -9999 \n",
      "\n",
      "10-31-2013 10:30:00, -2.693 \n",
      "\n",
      "10-31-2013 10:30:00, -2.693 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preview the content of the BeaverDivideTemp file\n",
    "air_temp_csv = 'BeaverDivideTemp.csv'\n",
    "with open(air_temp_csv) as f:\n",
    "    for i in range(0, 10):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Analysis\n",
    "\n",
    "Pandas is a data analysis library that we will be using to read and summarize our temperature data.  To get started, load the csv data into a Pandas DataFrame object using `read_csv`. This is a powerful function that allows us to skip commented lines, strip whitespace, as well as transform date strings into python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all of the data into pandas\n",
    "dateparse = lambda x: datetime.strptime(x, '%m-%d-%Y %H:%M:%S')\n",
    "df  = pandas.read_csv(air_temp_csv, comment='#', delimiter=',', parse_dates=['Date'], date_parser=dateparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine if nodata values are included. Often these are represented by a very large negative number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset our dataset to exclude nodata values. We'll also set a lower limit of -50C to remove any errors in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['AirTemp-degC'] > -50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use built-in Pandas functions to derive daily aggregate temperatures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_min = df.groupby(pandas.Grouper(key='Date', freq='1D')).min()\n",
    "daily_max = df.groupby(pandas.Grouper(key='Date', freq='1D')).max()\n",
    "daily_ave = df.groupby(pandas.Grouper(key='Date', freq='1D')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize our derived data by using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure\n",
    "fig, ax = plt.subplots(1,1,figsize=(15, 5))\n",
    "\n",
    "# plot each temperature time series\n",
    "tmax = daily_max.plot(ax=ax, style='r-')\n",
    "tmin = daily_min.plot(ax=ax, style='b-')\n",
    "tave = daily_ave.plot(ax=ax, style='g-')\n",
    "\n",
    "# display a legend\n",
    "ax.legend(['TMax', 'TMin', 'TAve'])\n",
    "\n",
    "# set the figure title\n",
    "fig.suptitle('Beaver Divide Temperatures')\n",
    "plt.ylabel('Temperature (degrees C)')\n",
    "\n",
    "# format the ticks\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine our data and save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "daily_min.rename(columns={'AirTemp-degC':'MinAirTemp'}, inplace=True)\n",
    "daily_max.rename(columns={'AirTemp-degC':'MaxAirTemp'}, inplace=True)\n",
    "daily_ave.rename(columns={'AirTemp-degC':'AveAirTemp'}, inplace=True)\n",
    "        \n",
    "# merge all the data\n",
    "df_merged = reduce(lambda  left,right: pandas.merge(left,right,on=['Date'], how='outer'), [daily_min, daily_max, daily_ave])\n",
    "\n",
    "# save to csv\n",
    "df_merged.to_csv('min_max_ave.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Save the results back into HydroShare\n",
    "\n",
    "Using the `hs_utils` library, the results of our timeseries analysis can be saved back into HydroShare.  First, define all of the required metadata for resource creation, i.e. *title*, *abstract*, *keywords*, and *content files*.  In addition, we must define the type of resource that will be created, in this case *genericresource*.  \n",
    "\n",
    "***Optional*** : define the resource from which this \"new\" content has been derived.  This is one method for tracking resource provenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define HydroShare required metadata\n",
    "title = 'Daily Aggregate Temperature for Beaver Divide'\n",
    "abstract = 'This daily average air temperature for the Beaver Divide gauging station that is maintained by iUtah researchers.'\n",
    "keywords = ['Temperatire', 'Beaver Divide', 'Time Series']\n",
    "\n",
    "# create a list of files that will be added to the HydroShare resource.\n",
    "data_files = ['BeaverDivideTemp.csv', 'min_max_ave.csv']  \n",
    "\n",
    "!hs create -t {title} -a {abstract} -k {' '.join(keywords)} -f {' '.join(data_files)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
